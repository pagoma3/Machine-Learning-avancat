{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4209d3a3",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "\n",
    "Take whichever English text you want and calculate word frequency:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "010eac93",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-24T10:58:52.741295Z",
     "start_time": "2021-08-24T10:58:49.125299Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import relevant libraries:\n",
    "\n",
    "import textract\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "from textblob import TextBlob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a1a7e47",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-24T10:58:52.930518Z",
     "start_time": "2021-08-24T10:58:52.747219Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 678),\n",
       " (',', 611),\n",
       " ('of', 506),\n",
       " ('shall', 306),\n",
       " ('.', 270),\n",
       " ('and', 264),\n",
       " ('to', 190),\n",
       " ('be', 179),\n",
       " ('or', 160),\n",
       " ('in', 148)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract text file content into a string object using the textract library:\n",
    "\n",
    "text = str(textract.process(\"us_constitution.txt\"))\n",
    "\n",
    "# Tokenise each word (make them into separate, countable entities):\n",
    "\n",
    "tokenized_word = word_tokenize(text)\n",
    "\n",
    "# Add up words to obtain word count. Then examine the most common words:\n",
    "\n",
    "fdist = FreqDist(tokenized_word)\n",
    "\n",
    "fdist.most_common(10)\n",
    "\n",
    "# Note that most of the most common words without filtering are irrelevant to obtain valuable information, such as \n",
    "# dots, commas or connector words. Hence, we must now filter them out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7a39ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T14:13:13.404765Z",
     "start_time": "2021-08-23T14:13:13.260577Z"
    }
   },
   "source": [
    "## Level 2\n",
    "\n",
    "### Exercise 3\n",
    "\n",
    "Remove the stopwords and do stemming to your data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b7fe248",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-24T11:01:14.888442Z",
     "start_time": "2021-08-24T11:01:14.853897Z"
    }
   },
   "outputs": [],
   "source": [
    "# Remove non-alphanumerical values:\n",
    "\n",
    "tokenized_word= [word for word in tokenized_word if word.isalnum()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8fbc61a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-24T11:01:14.957517Z",
     "start_time": "2021-08-24T11:01:14.938924Z"
    }
   },
   "outputs": [],
   "source": [
    "# To remove stopwords, we first set the language to English:\n",
    "\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "# We create a for loop that adds to a new array the filtered text:\n",
    "\n",
    "filtered_stop=[]\n",
    "\n",
    "for w in tokenized_word:\n",
    "    if w not in stop_words:\n",
    "        filtered_stop.append(w)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4fc91844",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-24T11:01:15.147375Z",
     "start_time": "2021-08-24T11:01:14.962083Z"
    }
   },
   "outputs": [],
   "source": [
    "# With another for loop we now get our word stems:\n",
    "ps = PorterStemmer()\n",
    "\n",
    "filtered_stem = []\n",
    "\n",
    "for w in filtered_stop:\n",
    "    filtered_stem.append(ps.stem(w))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88eee141",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-24T11:01:15.179748Z",
     "start_time": "2021-08-24T11:01:15.152693Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('shall', 306),\n",
       " ('state', 218),\n",
       " ('presid', 113),\n",
       " ('unit', 86),\n",
       " ('the', 80),\n",
       " ('congress', 63),\n",
       " ('offic', 57),\n",
       " ('amend', 54),\n",
       " ('law', 52),\n",
       " ('senat', 51),\n",
       " ('person', 49),\n",
       " ('may', 44),\n",
       " ('hous', 42),\n",
       " ('power', 41),\n",
       " ('vote', 41),\n",
       " ('repres', 35),\n",
       " ('year', 34),\n",
       " ('ratifi', 34),\n",
       " ('constitut', 33),\n",
       " ('articl', 29)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Frequency count of the filtered text:\n",
    "\n",
    "fdist_stem = FreqDist(filtered_stem)\n",
    "\n",
    "fdist_stem.most_common(20)\n",
    "\n",
    "# After filtering, the frequency count appears much more valuable. States, President, Unity, Congress all seem like\n",
    "# very relevant parts of a constitution.\n",
    "\n",
    "# It can be noticed that currently relevant political concepts are not explicitly mentioned in the Constitution.\n",
    "# Amongst them: democracy, rights, minority, parties, nation..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7883c98",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T14:25:18.237972Z",
     "start_time": "2021-08-23T14:25:18.223912Z"
    }
   },
   "source": [
    "## Level 3\n",
    "\n",
    "### Exercise 4\n",
    "\n",
    "Perform Sentiment Analysis on your dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b9816b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The resources provided indicated the use of a classification model that could be compared with a pre-existing \n",
    "# baseline, which is not the case of the US constitution. Instead, the sentiment analysis tools from NLTK and Text \n",
    "# Blob will be used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0031cbfc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-24T10:58:53.567780Z",
     "start_time": "2021-08-24T10:58:53.217949Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.061, 'neu': 0.828, 'pos': 0.111, 'compound': 0.9999}\n"
     ]
    }
   ],
   "source": [
    "# Through the Sentiment Intensity Analyser module of NLTK we can obtain the sentiment of the text overall\n",
    "\n",
    "vader_score = SentimentIntensityAnalyzer().polarity_scores(text)\n",
    "\n",
    "print(vader_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6a07051",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-24T10:58:53.715002Z",
     "start_time": "2021-08-24T10:58:53.579622Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=0.060844770455881596, subjectivity=0.3702974104085216)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The TextBlob library provides another insight into sentiment analysis:\n",
    "\n",
    "blob_score = TextBlob(text)\n",
    "\n",
    "blob_score.sentiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948ffaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# When evaluating the results, we should expect a high degree of objectivity/neutrality from a legal, objective text \n",
    "\n",
    "# According to the NLTK library analysis, the largest part of the text is neutral in sentiment. \n",
    "\n",
    "# According to the TextBlob library, the text stands in the middle of the polarity scale (from -1 to 1, negative \n",
    "# being negative sentiments and positive being positive), indicating a very low degree of polarity. It also stands \n",
    "# low in the scale of subjectivity (from 0, most objective, to 1, most subjective), although not excessively so."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
